{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-YbjCkzw0yU",
        "outputId": "aa523290-ffa0-4341-e76c-1215381adf7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 14.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 498.0 MB 12 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 56.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 60.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 60.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U \"tensorflow-text==2.8.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-P1ZOA0FkVJ",
        "outputId": "098af810-9f41-4765-ac30-47f73e50ed82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 13.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 58.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 56.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 238 kB 81.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 73.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 76.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tf-models-official==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0oO5yMYjwjy",
        "outputId": "2a72dbcf-fd6a-49be-fbb6-4e1d5a993d6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import string\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from official.nlp import optimization \n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yaSl6MWVmdE_"
      },
      "outputs": [],
      "source": [
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytwyltjfjba9",
        "outputId": "c242a0dc-7172-4548-b8f7-2bb3167f218b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-20 07:33:53--  https://github.com/jgolbeck/fakenews/blob/master/FakeNewsData.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/jgolbeck/fakenews/raw/master/FakeNewsData.zip [following]\n",
            "--2022-12-20 07:33:54--  https://github.com/jgolbeck/fakenews/raw/master/FakeNewsData.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/jgolbeck/fakenews/master/FakeNewsData.zip [following]\n",
            "--2022-12-20 07:33:54--  https://raw.githubusercontent.com/jgolbeck/fakenews/master/FakeNewsData.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3002233 (2.9M) [application/zip]\n",
            "Saving to: ‘/tmp/FakeNewsData.zip’\n",
            "\n",
            "/tmp/FakeNewsData.z 100%[===================>]   2.86M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-12-20 07:33:55 (119 MB/s) - ‘/tmp/FakeNewsData.zip’ saved [3002233/3002233]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/jgolbeck/fakenews/blob/master/FakeNewsData.zip?raw=true\" \\\n",
        "    -O \"/tmp/FakeNewsData.zip\"\n",
        "\n",
        "local_zip = '/tmp/FakeNewsData.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7pugj8vlGTR"
      },
      "source": [
        "Now the images are stored within the `/tmp/FakeNewsData` directory. There is a subdirectory for each class, so one for fake and one for satire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BVAvKLtk3fE",
        "outputId": "9d34b9e5-ffd7-4b01-ebb7-4d62a984a073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 284 texts of fake.\n",
            "There are 204 texts of satire.\n"
          ]
        }
      ],
      "source": [
        "source_path = '/tmp/FakeNewsData/StoryText 2'\n",
        "\n",
        "source_path_fake = os.path.join(source_path, 'Fake/finalFake')\n",
        "source_path_satire = os.path.join(source_path, 'Satire/finalSatire')\n",
        "\n",
        "\n",
        "# os.listdir returns a list containing all files under the given path\n",
        "print(f\"There are {len(os.listdir(source_path_fake))} texts of fake.\")\n",
        "print(f\"There are {len(os.listdir(source_path_satire))} texts of satire.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GlUcTtuEnIQ7"
      },
      "outputs": [],
      "source": [
        "# Defining root directory\n",
        "root_dir = '/tmp/fkae-or-satire'\n",
        "\n",
        "# Empty directory to prevent FileExistsError is the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "  shutil.rmtree(root_dir)\n",
        "\n",
        "# Create_train_test_dirs\n",
        "def create_train_test_dirs(root_path):\n",
        "\n",
        "  train_dir = os.path.join(root_path, 'training')\n",
        "  test_dir = os.path.join(root_path, 'testing')\n",
        "  os.makedirs(train_dir)\n",
        "  os.makedirs(test_dir)\n",
        "\n",
        "  # Directory with training cat/dog pictures\n",
        "  train_fake_dir = os.path.join(train_dir, 'fake')\n",
        "  train_satire_dir = os.path.join(train_dir, 'satire')\n",
        "  os.makedirs(train_fake_dir)\n",
        "  os.makedirs(train_satire_dir)\n",
        "\n",
        "  # Directory with test cat/dog pictures\n",
        "  test_fake_dir = os.path.join(test_dir, 'fake')\n",
        "  test_satire_dir = os.path.join(test_dir, 'satire')\n",
        "  os.makedirs(test_fake_dir)\n",
        "  os.makedirs(test_satire_dir)\n",
        "\n",
        "  pass\n",
        "  \n",
        "try:\n",
        "  create_train_test_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIGrrYb3n52n",
        "outputId": "f2f46b19-f85a-44a5-868a-de991652c80b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/tmp/fkae-or-satire/training\n",
            "/tmp/fkae-or-satire/testing\n",
            "/tmp/fkae-or-satire/training/fake\n",
            "/tmp/fkae-or-satire/training/satire\n",
            "/tmp/fkae-or-satire/testing/fake\n",
            "/tmp/fkae-or-satire/testing/satire\n"
          ]
        }
      ],
      "source": [
        "# Testing create_train_test_dirs function\n",
        "\n",
        "for rootdir, dirs, files in os.walk(root_dir):\n",
        "    for subdir in dirs:\n",
        "        print(os.path.join(rootdir, subdir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Cd2k95o7ia"
      },
      "source": [
        "Random split and clean the text before copy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w_Is8CcJDDZK"
      },
      "outputs": [],
      "source": [
        "def remove_urls(text):\n",
        "    # Use a regular expression to match URLs\n",
        "    url_pattern = r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'\n",
        "    return re.sub(url_pattern, '', text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "clean_text(text) - remove urls, remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a function to handle text data cleaning\n",
        "def clean_text(text):\n",
        "    url_pattern = r'(http|https):\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)'\n",
        "    text_filtered = re.sub(url_pattern, '', text)\n",
        "\n",
        "    text_filtered = \"\".join([word.lower() for word in text_filtered if word not in string.punctuation])\n",
        "    tokens = re.split('\\W+', text_filtered)\n",
        "    text_filtered = (\" \").join([word for word in tokens if word not in stopwords])\n",
        "\n",
        "    # Use a regular expression to match URLs\n",
        "    return text_filtered\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "S_mKV16foM5T"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#  Split_data\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "  if(SPLIT_SIZE % 1 == 0):\n",
        "    SPLIT_SIZE = 0.25\n",
        "  news = os.listdir(SOURCE)\n",
        "  news_test , news_train =  train_test_split(news, test_size = SPLIT_SIZE, shuffle  = True) \n",
        "\n",
        "  for text in news_train:\n",
        "    if(os.path.getsize(os.path.join(SOURCE,text)) == 0):\n",
        "      print(text,\" is zero length, so ignoring.\")\n",
        "    else:\n",
        "        with open(os.path.join(SOURCE, text), 'r', encoding='ascii',errors='ignore') as f:\n",
        "            contents = f.read()\n",
        "            cleaned_text = clean_text(contents)\n",
        "        with open(os.path.join(TRAINING,text), 'w') as f:\n",
        "            # Write the cleaned text to the file\n",
        "            f.write(cleaned_text)\n",
        "\n",
        "  for text in news_test:\n",
        "    if(os.path.getsize(os.path.join(SOURCE,text)) == 0):\n",
        "      print(text, \" is zero length, so ignoring.\")\n",
        "    else:\n",
        "        with open(os.path.join(SOURCE, text), 'r', encoding='ascii',errors='ignore') as f:\n",
        "            contents = f.read()\n",
        "            cleaned_text = clean_text(contents)\n",
        "        with open(os.path.join(TESTING,text), 'w') as f:\n",
        "            # Write the cleaned text to the file\n",
        "            f.write(cleaned_text)\n",
        "\n",
        "  pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvWZIB3wpTNM",
        "outputId": "45610e82-b14a-4903-8746-d4a82243a051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "There are 199 texts of fake for training\n",
            "There are 143 texts of satire for training\n",
            "There are 85 texts of cats fake testing\n",
            "There are 61 texts of satire for testing\n"
          ]
        }
      ],
      "source": [
        "# Test split_data function\n",
        "\n",
        "# Define paths\n",
        "FAKE_SOURCE_DIR = os.path.join(source_path, 'Fake/finalFake')\n",
        "SATIRE_SOURCE_DIR = os.path.join(source_path, 'Satire/finalSatire')\n",
        "\n",
        "TRAINING_DIR = \"/tmp/fkae-or-satire/training/\"\n",
        "TESTING_DIR = \"/tmp/fkae-or-satire/testing/\"\n",
        "\n",
        "TRAINING_FAKE_DIR = os.path.join(TRAINING_DIR, \"fake/\")\n",
        "TESTING_FAKE_DIR = os.path.join(TESTING_DIR, \"fake/\")\n",
        "\n",
        "TRAINING_SATIRE_DIR = os.path.join(TRAINING_DIR, \"satire/\")\n",
        "TESTING_SATIRE_DIR = os.path.join(TESTING_DIR, \"satire/\")\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "if len(os.listdir(TRAINING_FAKE_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_FAKE_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_SATIRE_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_SATIRE_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_FAKE_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_FAKE_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_SATIRE_DIR)) > 0:\n",
        "  for file in os.scandir(TESTING_SATIRE_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "# Define proportion of texts used for training\n",
        "split_size = .7\n",
        "\n",
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_data(FAKE_SOURCE_DIR, TRAINING_FAKE_DIR, TESTING_FAKE_DIR, split_size)\n",
        "split_data(SATIRE_SOURCE_DIR, TRAINING_SATIRE_DIR, TESTING_SATIRE_DIR, split_size)\n",
        "\n",
        "# Check that the number of images matches the expected output\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_FAKE_DIR))} texts of fake for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_SATIRE_DIR))} texts of satire for training\")\n",
        "print(f\"There are {len(os.listdir(TESTING_FAKE_DIR))} texts of cats fake testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_SATIRE_DIR))} texts of satire for testing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laGxLXzqJ9mp",
        "outputId": "2169ca71-bac8-4a09-e150-98d659acba49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 341 files belonging to 2 classes.\n",
            "Using 273 files for training.\n",
            "Found 341 files belonging to 2 classes.\n",
            "Using 68 files for validation.\n",
            "Found 145 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "batch_size = 16\n",
        "seed = 42\n",
        "\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    TRAINING_DIR,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed)\n",
        "\n",
        "class_names = raw_train_ds.class_names\n",
        "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    TRAINING_DIR,\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed)\n",
        "\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    TESTING_DIR,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScBO2U-AMQkb"
      },
      "source": [
        "## **Some news examples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD-Y-mcGMHeq",
        "outputId": "5a30e6f4-c768-4a19-8b4a-07982de9b658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: b'npr 25 million votes clinton completely fake lost popular vote study published npr reveals 25 million hillary clinton votes completely fraudulent meaning democratic candidate actually lost popular vote huge margin study pew center claiming 800000 noncitizens voted hillary clinton failed take account dead fraudulent voters totalled 25 million registered voters according reports illegal aliens combined dead voters multiple state voters explains hillary appeared popular vote trump years presidential race report pew center states finds 18 million dead people currently registered vote 24 million registrations either invalid inaccurate npr reported 2012 ironic given npr heavily controlled democrats many dead registered voters somehow keep voting democrat beyond grave recently philadelphia penn colorado also worth noting us population increased since 2012 meaning theres likely dead invalid voters pew study found almost 3 million people registered vote one state npr added thats new resident registers vote state officials usually never bother tell former state change voter residency catch release immigration program obama administration illegal aliens routinely given bus tickets travel states immigration officials theoretically possible noncitizens register vote border country illegally register vote another state taxpayerfunded bus dropped clinton 163 populous counties us account half total votes election including dense urban areas new york california yet popular vote 28 million votes reveals lack enthusiasm voters comparison trump democrats would depended illegal votes portion 24 million invalid voter registrations combined portion 18 million dead voters 800000 known illegal voters could explain difference 28 million votes worth noting 800000 figure could low conservative estimate said popular vote victory meaningless president elected popular vote trump clinton would campaigned entirely different states densely population regions us would decide would become president without electoral college united states america would reduced united states new york california 48 vassal states yet notice clinton campaigned less populated states knew popular vote meaningless ahead election however popular vote useful barometer voter fraud since populous countries also susceptible election tampering illegal invalid dead voters '\n",
            "Label : 0 (fake)\n",
            "Review: b'obama resign january 1st amid new benghazi revelations according several seniorranking white house officials president barack obama resign office january 1st 2015 learning socalled smoking gun story regarding benghazi scandal soon revealed sources claim obama announce resignation shortly midterm elections november decision resign came reporters fox news allegedly contacted august survivor 2012 benghazi terrorist attack came forward shocking video evidence obama white house chief staff jacob lew secretary state hillary clinton knew attack us diplomatic facility benghazi libya imminent intentionally ordered key security personnel leave facility travel eight blocks away sources fox news say unidentified survivor allegedly recorded video teleconference cell phone lew gave orders obama clinton watched dont want guy like mitt romney deciding budget lew supposedly states video fox news yet released need win thing means need make sacrifices let clear one harmed sacrificing buckets paint thats need little nudge polls sources fox say network prepared air video august 23rd house oversight chairman darrell issa rca convinced hold releasing footage white house sources say two unidentified reporters fox news joined issa private meeting obama past weekend august 30th agreed reveal video obama agreed resign white house senior staff negotiated issa reporters obama could stay office end year would announce resignation november shortly midterms agreed terms unclear obamas resignation highly sought conservatives tea party figures since well actually took office january 2009 benghazi scandal continues ignite fiery debate across united states despite full lack evidence wrongdoing behalf obama administration august learned republicanled house intelligence committee cleared obama team wrongdoing benghazi scandal story proves true obama resign noon january 1st 2015 vice president joe biden sworn office unclear next vice president incumbent white house chief staff denis mcdonough strongly favored role bidens office reportedly scheduled emergency meetings nancy pelosi tim kaine elizabeth warren maryland governor martin omalley tuesday wednesday speculate meetings might related future vp decision though sources could confirm rumor'\n",
            "Label : 0 (fake)\n",
            "Review: b'trump disgusted french copied tower paris las vegas hotel paris dpo scandal takes hold donald trumps trip france visit capital president united states became enraged french shamelessly copied tower famous paris las vegas hotel nevada usa president trump explained fighting back nations simply appropriating symbols american culture way president already taken aback learned french capital also called paris like famous hotel las vegas stage could still coincidence opined trump pretty popular name paris hiltons called paris however observed distinctive shape tower brazen conterfeit could mistaken know cheap copy see one us president reported told french president emmanuel macron fury practically exact copy paris las vegas tower know thing two hotels casinos angered trump accept objections host emmanuel macron either audacity claim completely way around greatest country world would need copy anyone else fact half world business copying american landmarks hear several buildings egypt poorquality copies famous luxor casino las vegas china even several whole cities look like chinatown new york president trump explained would work ensure impudent counterfeiters either demolish replicas pay royalties usa otherwise fears french may also one day build copy statue liberty'\n",
            "Label : 1 (satire)\n",
            "Review: b'president trump fires 14 muslim federal judges barack obama managed pack federal judiciary bleeding heart liberals professional lobbyists climate change sciencefiction scams 15 moslems none born country president trump choice fire one last month ruled sharia law ok defendant moslem reasonably expected follow faith face eternity hell force christian pay birth control indigents gutter rats cant ask moslem beat wife sounds right today president trump quietly ended tenure moslem 14 named little group allah worshippers executive order eliminating benches altogether white house propaganda director emmanuel goldstein told fox news president trump doesnt authority remove federal judge appointed confirmed senate authority determine number benches judiciary per evacuation clause reduced number today 14 brilliant thats voted president trump well vote hes waaaaaaay smarter well keep updated fate moslems'\n",
            "Label : 1 (satire)\n"
          ]
        }
      ],
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(4):\n",
        "    print(f'Review: {text_batch.numpy()[i]}')\n",
        "    label = label_batch.numpy()[i]\n",
        "    print(f'Label : {label} ({class_names[label]})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8_ctG55-uTX",
        "outputId": "5bf25693-a515-469b-e3c0-4d90f02b12bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ],
      "source": [
        "#@title Choose a BERT model to fine-tune\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-2_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1O6-45wdYrO",
        "outputId": "bce1a181-a7e0-403b-b0ec-798b70923132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.6 MB 11.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 511.8 MB 27 kB/s \n",
            "\u001b[K     |████████████████████████████████| 438 kB 72.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 64.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 57.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U \"tensorflow-text==2.9.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XO54dLOaUBNv"
      },
      "outputs": [],
      "source": [
        "import tensorflow_text\n",
        "\n",
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_EtxkY4DqeFW"
      },
      "outputs": [],
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.3)(net)\n",
        "  net = tf.keras.layers.Dense(128)(net)\n",
        "  net = tf.keras.layers.Dropout(0.2)(net)\n",
        "  net = tf.keras.layers.Dense(16)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dUudyjR0wqQd"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6dzFzuNrlal",
        "outputId": "790dd37f-6e38-4643-a401-f049c8648f13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.26133057]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "classifier_model = build_classifier_model()\n",
        "bert_raw_result = classifier_model(tf.constant(['text_test']))\n",
        "print(tf.sigmoid(bert_raw_result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "djMr2QElsEQ4"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()\n",
        "\n",
        "epochs = 5\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "\n",
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-wtRF6YsWU4",
        "outputId": "c7cd7265-e151-469c-cfc9-cca40eda085b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f0836258c10> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "17/18 [===========================>..] - ETA: 0s - loss: 0.8664 - binary_accuracy: 0.5735WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f0818fb6ca0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "18/18 [==============================] - 13s 294ms/step - loss: 0.8647 - binary_accuracy: 0.5751 - val_loss: 0.7254 - val_binary_accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 0.6987 - binary_accuracy: 0.6447 - val_loss: 0.6742 - val_binary_accuracy: 0.5294\n",
            "Epoch 3/15\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 0.6040 - binary_accuracy: 0.6996 - val_loss: 0.6582 - val_binary_accuracy: 0.5735\n",
            "Epoch 4/15\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 0.5077 - binary_accuracy: 0.7326 - val_loss: 0.6591 - val_binary_accuracy: 0.5882\n",
            "Epoch 5/15\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 0.4998 - binary_accuracy: 0.7473 - val_loss: 0.6637 - val_binary_accuracy: 0.6324\n",
            "Epoch 6/15\n",
            "18/18 [==============================] - 2s 85ms/step - loss: 0.4639 - binary_accuracy: 0.8095 - val_loss: 0.6637 - val_binary_accuracy: 0.6324\n",
            "Epoch 7/15\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 0.4728 - binary_accuracy: 0.7802 - val_loss: 0.6637 - val_binary_accuracy: 0.6324\n",
            "Epoch 8/15\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 0.4795 - binary_accuracy: 0.7802 - val_loss: 0.6637 - val_binary_accuracy: 0.6324\n",
            "Epoch 9/15\n",
            "18/18 [==============================] - 2s 88ms/step - loss: 0.4613 - binary_accuracy: 0.7839 - val_loss: 0.6637 - val_binary_accuracy: 0.6324\n",
            "Epoch 10/15\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 0.4586 - binary_accuracy: 0.7619 - val_loss: 0.6637 - val_binary_accuracy: 0.6324\n",
            "Epoch 11/15\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 0.5285 - binary_accuracy: 0.7363 - val_loss: 0.6637 - val_binary_accuracy: 0.6324\n",
            "Epoch 12/15\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 0.5128 - binary_accuracy: 0.7363 - val_loss: 0.6637 - val_binary_accuracy: 0.6324\n",
            "Epoch 13/15\n",
            "18/18 [==============================] - 2s 89ms/step - loss: 0.5194 - binary_accuracy: 0.7326 - val_loss: 0.6637 - val_binary_accuracy: 0.6324\n",
            "Epoch 14/15\n",
            "18/18 [==============================] - 2s 86ms/step - loss: 0.4745 - binary_accuracy: 0.7729 - val_loss: 0.6637 - val_binary_accuracy: 0.6324\n",
            "Epoch 15/15\n",
            "18/18 [==============================] - 2s 87ms/step - loss: 0.5614 - binary_accuracy: 0.7253 - val_loss: 0.6637 - val_binary_accuracy: 0.6324\n"
          ]
        }
      ],
      "source": [
        "history = classifier_model.fit(x=train_ds,\n",
        "                              epochs=15,\n",
        "                              # batch_size=16,\n",
        "                              validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwP-czFswSN8",
        "outputId": "7139105e-98db-4548-d0c7-8dac6131705c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " BERT_encoder (KerasLayer)      {'pooled_output': (  22458881    ['preprocessing[0][0]',          \n",
            "                                None, 512),                       'preprocessing[0][1]',          \n",
            "                                 'encoder_outputs':               'preprocessing[0][2]']          \n",
            "                                 [(None, 128, 512),                                               \n",
            "                                 (None, 128, 512)],                                               \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 512),                                                \n",
            "                                 'default': (None,                                                \n",
            "                                512)}                                                             \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 512)          0           ['BERT_encoder[0][3]']           \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          65664       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 16)           2064        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " classifier (Dense)             (None, 1)            17          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 22,526,626\n",
            "Trainable params: 22,526,625\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classifier_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TeCVL7MG0tk",
        "outputId": "c53cf486-b277-4e22-fe22-2d1e3755e699"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "bmF7KyRqGnk_",
        "outputId": "1aa3a29e-4799-4a05-a1b3-d4ac9fc7a63d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['binary_accuracy']\n",
        "val_acc = history.history['val_binary_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7h_7ozXeGvJC",
        "outputId": "d0c8ba2a-9cbd-41c7-e9a4-50b543e584a3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.clf()   # clear figure\n",
        "acc_values = history_dict['binary_accuracy']\n",
        "val_acc_values = history_dict['val_binary_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_IooiEPlBKi"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8qKIqxFlAWq",
        "outputId": "bcab7123-ec63-4151-edb7-7c52286133e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 64). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7f081989c9d0> and will run it as-is.\n",
            "Cause: could not parse the source code of <function _trace_resource_initializers.<locals>._wrap_obj_initializer.<locals>.<lambda> at 0x7f081989c9d0>: no matching AST found among candidates:\n",
            "# coding=utf-8\n",
            "(lambda : _wrap_initializer(obj))\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ],
      "source": [
        "dataset_name = 'FakeNewsData'\n",
        "saved_model_path = './{}_bert'.format(dataset_name.replace('/', '_'))\n",
        "\n",
        "classifier_model.save(saved_model_path, include_optimizer=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FIQFANqylNmn"
      },
      "outputs": [],
      "source": [
        "reloaded_model = tf.saved_model.load(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Quk4uckml0Fl",
        "outputId": "7023d786-fdc6-4b13-e994-443d6ce92c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./FakeNewsData_bert\n"
          ]
        }
      ],
      "source": [
        "print(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKOKeUruvY86",
        "outputId": "4ba7d8d9-b33d-4526-c3aa-1bd99733b976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results from the saved model:\n",
            "input: spicer trump led brexit successfully upperclass eloquent english skills wednesdays press briefing white house press secretary sean spicer gave strange response european commission president jeanclaude junker criticized president donald trumps comprehension world affairs last week junker warned countries may leave european union trumps administration applauded britains departure eu think president well steeped world affairs especially europe nato issues spicer insisted leader effort call brexit know asked comment whether connection president trumps position brexit fact majority britains citizens voted leaving eu spicer argued british smitten billionaire businessmanturnedpresidents language skills decided hear know president trump citizens uk havent really gotten right foot speak think remember one point even petition floating around ban donald trump entering great britain spicer reminded members press however ask british today felt president believe would encounter different responses continued personal opinion belief british people became smitten fact donald trump one point spoke upperclass eloquent english realized okay person make matters even obvious president trump scottish heritage mothers side theres also im well aware fact english scottish dont always see eye eye despite union would seem managed find common ground comes president donald trump asked elaborate trumps rumored eloquent language skills press secretary argued even though trumps language muchdisputed point campaign donald trump known extremely hard worker selfmade billionaire also said thats comes surprise able improve language point became favorite citizens country language first originated put perspective talking england know pretty much nothing left show complicated language rules extremely broad dictionary end day im going say english voted leave eu donald trump said would good idea however would like believe deep listened really heard saying precisely speaking nice language compare situation theyre debating whether theyre going let country think thats equivalent climbing mount everest matter minutes huge undertaking way fact mount everests summit cold british towards americans makes sweeter would imagine spicer concluded : score: 0.634252\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def print_my_examples(inputs, results):\n",
        "  result_for_printing = \\\n",
        "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
        "                         for i in range(len(inputs))]\n",
        "  print(*result_for_printing, sep='\\n')\n",
        "  print()\n",
        "\n",
        "\n",
        "examples = [\n",
        "    'spicer trump led brexit successfully upperclass eloquent english skills wednesdays press briefing white house press secretary sean spicer gave strange response european commission president jeanclaude junker criticized president donald trumps comprehension world affairs last week junker warned countries may leave european union trumps administration applauded britains departure eu think president well steeped world affairs especially europe nato issues spicer insisted leader effort call brexit know asked comment whether connection president trumps position brexit fact majority britains citizens voted leaving eu spicer argued british smitten billionaire businessmanturnedpresidents language skills decided hear know president trump citizens uk havent really gotten right foot speak think remember one point even petition floating around ban donald trump entering great britain spicer reminded members press however ask british today felt president believe would encounter different responses continued personal opinion belief british people became smitten fact donald trump one point spoke upperclass eloquent english realized okay person make matters even obvious president trump scottish heritage mothers side theres also im well aware fact english scottish dont always see eye eye despite union would seem managed find common ground comes president donald trump asked elaborate trumps rumored eloquent language skills press secretary argued even though trumps language muchdisputed point campaign donald trump known extremely hard worker selfmade billionaire also said thats comes surprise able improve language point became favorite citizens country language first originated put perspective talking england know pretty much nothing left show complicated language rules extremely broad dictionary end day im going say english voted leave eu donald trump said would good idea however would like believe deep listened really heard saying precisely speaking nice language compare situation theyre debating whether theyre going let country think thats equivalent climbing mount everest matter minutes huge undertaking way fact mount everests summit cold british towards americans makes sweeter would imagine spicer concluded',\n",
        "\n",
        "]\n",
        "\n",
        "reloaded_results = tf.sigmoid(reloaded_model(tf.constant(examples)))\n",
        "original_results = tf.sigmoid(classifier_model(tf.constant(examples)))\n",
        "\n",
        "print('Results from the saved model:')\n",
        "print_my_examples(examples, reloaded_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g2g6qVw2jyi",
        "outputId": "1f316bd4-523e-46f1-fccb-405f1a19de04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "print(round(float(reloaded_results)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
